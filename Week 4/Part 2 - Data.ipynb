{
    "cells": [
        {
            "metadata": {
                "collapsed": true
            },
            "cell_type": "markdown",
            "source": "Data Description 2.1 Data Sources\n\nNeighbourhood Source\n\nThe data pertaining to the neighbourhoods of Trondheim will be taken from the url: https://en.wikipedia.org/wiki/Lerkendal The information in this link is contained in a table towards the bottom, it includes the four boroughs the city is divided into with their respective neighbourhoods alongside. The data will have to be transformed as it needs other data appending to it.\n\nProperty price source\n\nIt was initially planned to include property prices by region but upon reflection and the search for data, obtaining commercial property prices by neighbourhood for Trondheim is not going to be possible. The housing market in Trondheim is complex and very little data is compiled within one place to be able to scrape and have confidence it is accurate. Few properties are bought and sold in the city and its especially rare to get listings for anything other than apartments which would not be suitable for this business start-up. In this regard, an alternative is availability of transport in certain areas.\n\nFoursquare API\n\nThe source of data to be taken from the Foursquare API includes:\n\n\u2022\tavailability of restaurants and stores etc. \n\nThe client would like to have information to plan for the future which involves quality of life for future employees. For this, the Foursquare API is going to be used to analyse the number of services available in each borough.\n\n2.2 Data Cleaning\n\nIn order to obtain the latitude and longitude data I used the python package geopy. The data fed into this package did not contain the postal codes of the locations, so the data was fed in following the format: '{}, Trondheim, NORWAY'.format(Neighbourhood, Borough). The iteration of this list output five erroneous results which were obviously not neighbourhood coordinates in Trondheim. There were two districts in Denmark, one in Finland, one in Italy and the fifth in the USA. Noticing this, I went back to input these locations through the geopy package manually and replaced the latitudes and longitudes in the compiled list. If the list were longer and number of errors larger, it would be much more difficult to spot these results and fix them manually. Plotting the locations on a graph also helped to spot these though and had it been more difficult to fix manually, I would have devised another method to rectify the issue, perhaps spending an extra step finding the postcodes of the neighbourhoods."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.7.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}